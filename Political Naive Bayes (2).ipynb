{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michael Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Script\n",
    "sw = stopwords.words(\"english\")\n",
    "punctuation = set(punctuation) \n",
    "tw_punct = punctuation - {\"#\", \"'\"}\n",
    "\n",
    "def remove_stop(text, sw=sw) :\n",
    "    # modify this function to remove stopwords\n",
    "    return([ch for ch in text if ch not in sw])\n",
    "\n",
    "\n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "   text = [''.join(ch for ch in word if ch not in punct_set)\n",
    "           for word in text]\n",
    "   \n",
    "   return(text)\n",
    "\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    text = text.strip().split()\n",
    "    return(text)\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    # Remove punctuations\n",
    "    text = ''.join(ch for ch in text if ch not in punctuation)\n",
    "    \n",
    "    # Convert text to lower case and split into words\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    text = [word for word in text if word not in sw]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"C:/Users/micha/applied text mining/mod 4/2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventions\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Get all results\n",
    "tables = convention_cur.fetchall()\n",
    "\n",
    "# See table\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party FROM conventions\n",
    "    '''\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    text, party = row\n",
    "    text = clean_tokenize(text)\n",
    "    convention_data.append([text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['never',\n",
       "   'raised',\n",
       "   'way',\n",
       "   'would',\n",
       "   'running',\n",
       "   'public',\n",
       "   'office',\n",
       "   'didnâ€™t',\n",
       "   'interest',\n",
       "   'graduated',\n",
       "   'college',\n",
       "   'got',\n",
       "   'married',\n",
       "   'five',\n",
       "   'children',\n",
       "   'six',\n",
       "   'years',\n",
       "   'life',\n",
       "   'children',\n",
       "   'grown',\n",
       "   'opportunity',\n",
       "   'run',\n",
       "   'congress',\n",
       "   'came',\n",
       "   'along'],\n",
       "  'Democratic'],\n",
       " [['work',\n",
       "   'hard',\n",
       "   'contribute',\n",
       "   'community',\n",
       "   'pay',\n",
       "   'taxes',\n",
       "   'iâ€™ve',\n",
       "   'gone',\n",
       "   'school',\n",
       "   'built',\n",
       "   'good',\n",
       "   'life',\n",
       "   'two',\n",
       "   'daughters'],\n",
       "  'Democratic'],\n",
       " [['joe', 'bidenâ€™s', 'granddaughter', 'interview', 'take', 'one'],\n",
       "  'Democratic'],\n",
       " [['internationally',\n",
       "   'weâ€™ve',\n",
       "   'turned',\n",
       "   'back',\n",
       "   'agreements',\n",
       "   'forged',\n",
       "   'husband',\n",
       "   'alliances',\n",
       "   'championed',\n",
       "   'presidents',\n",
       "   'like',\n",
       "   'reagan',\n",
       "   'eisenhower',\n",
       "   'home',\n",
       "   'george',\n",
       "   'floyd',\n",
       "   'brianna',\n",
       "   'taylor',\n",
       "   'never',\n",
       "   'ending',\n",
       "   'list',\n",
       "   'innocent',\n",
       "   'people',\n",
       "   'color',\n",
       "   'continue',\n",
       "   'murdered',\n",
       "   'stating',\n",
       "   'simple',\n",
       "   'fact',\n",
       "   'black',\n",
       "   'life',\n",
       "   'matters',\n",
       "   'still',\n",
       "   'met',\n",
       "   'derision',\n",
       "   'nationâ€™s',\n",
       "   'highest',\n",
       "   'office',\n",
       "   'whenever',\n",
       "   'look',\n",
       "   'white',\n",
       "   'house',\n",
       "   'leadership',\n",
       "   'consolation',\n",
       "   'semblance',\n",
       "   'steadiness',\n",
       "   'get',\n",
       "   'instead',\n",
       "   'chaos',\n",
       "   'division',\n",
       "   'total',\n",
       "   'utter',\n",
       "   'lack',\n",
       "   'empathy'],\n",
       "  'Democratic'],\n",
       " [['team', 'usa', 'indeed', 'take', 'home', 'gold'], 'Republican'],\n",
       " [['united', 'states', 'america'], 'Democratic'],\n",
       " [['every',\n",
       "   'day',\n",
       "   'get',\n",
       "   'ask',\n",
       "   'hope',\n",
       "   'heâ€™s',\n",
       "   'proud',\n",
       "   'thatâ€™s',\n",
       "   'inaudible',\n",
       "   '020149',\n",
       "   'makes',\n",
       "   'move'],\n",
       "  'Democratic'],\n",
       " [['however',\n",
       "   'donald',\n",
       "   'trump',\n",
       "   'office',\n",
       "   'attempts',\n",
       "   'undermine',\n",
       "   'united',\n",
       "   'states',\n",
       "   'postal',\n",
       "   'service',\n",
       "   'extremely',\n",
       "   'concerned'],\n",
       "  'Democratic'],\n",
       " [['youâ€™re', 'okay'], 'Democratic'],\n",
       " [['administrationâ€™s',\n",
       "   'decision',\n",
       "   'provide',\n",
       "   'necessary',\n",
       "   'funding',\n",
       "   'united',\n",
       "   'states',\n",
       "   'postal',\n",
       "   'service',\n",
       "   'appalling'],\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw):\n",
    "    ret_dict = dict()\n",
    "    #split text\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw):\n",
    "    #marking fw\n",
    "    ret_dict = dict()\n",
    "    for word in text: \n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The most informative features shows distinct focuses for each party, for example, 'climate' and 'votes' for Democrats and 'china' and 'trade' for Republicans. Also, there are more aggressive tone in Republican tweets with words like 'destroy' and 'enemy'. Words like 'liberal' appearing more in Republican tweets can mean that they are tweets referring to their political opponents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"C:/Users/micha/applied text mining/mod 4/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for candidate, party, tweet in results:\n",
    "    # Decode byte-string\n",
    "    decoded_tweet = tweet.decode('utf-8') \n",
    "    # Split tweet into words\n",
    "    words = decoded_tweet.split() \n",
    "    tweet_data.append((words, party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['\"Brooks', 'Joins', 'Alabama', 'Delegation', 'in', 'Voting', 'Against', 'Flawed', 'Funding', 'Bill\"', 'http://t.co/3CwjIWYsNq'], 'Republican'), (['\"Brooks:', 'Senate', 'Democrats', 'Allowing', 'President', 'to', 'Give', 'Americansâ€™', 'Jobs', 'to', 'Illegals\"', '#securetheborder', 'https://t.co/mZtEaX8xS6'], 'Republican'), (['\"NASA', 'on', 'the', 'Square\"', 'event', 'this', 'Sat.', '11AM', 'â€“', '4PM.', 'Stop', 'by', '&amp;', 'hear', 'about', 'the', 'incredible', 'work', 'done', 'in', '#AL05!', '@DowntownHSV', 'http://t.co/R9zY8WMEpA'], 'Republican'), (['\"The', 'trouble', 'with', 'Socialism', 'is', 'that', 'eventually', 'you', 'run', 'out', 'of', 'other', \"people's\", 'money.\"', '-', 'Margaret', 'Thatcher', 'https://t.co/X97g7wzQwJ'], 'Republican'), (['\"The', 'trouble', 'with', 'socialism', 'is', 'eventually', 'you', 'run', 'out', 'of', 'other', \"people's\", 'money\"', 'â€“', 'Thatcher.', \"She'll\", 'be', 'sorely', 'missed.', 'http://t.co/Z8gBnDQUh8'], 'Republican')]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Republican': 288531, 'Democratic': 376125}\n"
     ]
    }
   ],
   "source": [
    "party_counts = {}\n",
    "for item in tweet_data:\n",
    "    party = item[1]  # assuming the party is the second element of each sublist\n",
    "    if party not in party_counts:\n",
    "        party_counts[party] = 0\n",
    "    party_counts[party] += 1\n",
    "print(party_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: ['Earlier', 'today,', 'I', 'spoke', 'on', 'the', 'House', 'Floor', 'abt', 'protecting', 'health', 'care', 'for', 'women', 'and', 'praised', '@PPmarmonte', 'for', 'their', 'work', 'on', 'the', 'Central', 'Coast.', 'https://t.co/WqgTRzT7VV']\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Go', 'Tribe!', '#RallyTogether', 'https://t.co/0NXutFL9L5']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Apparently,', 'Trump', 'thinks', \"it's\", 'just', 'too', 'easy', 'for', 'students', 'overwhelmed', 'by', 'the', 'crushing', 'burden', 'of', 'debt', 'to', 'pay', 'off', 'student', 'loans', '#TrumpBudget', 'https://t.co/ckYQO5T0Qh']\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Weâ€™re', 'grateful', 'for', 'our', 'first', 'responders,', 'our', 'rescue', 'personnel,', 'our', 'firefighters,', 'our', 'police,', 'and', 'volunteers', 'who', 'have', 'been', 'working', 'tirelessly', 'to', 'keep', 'people', 'safe,', 'provide', 'much-needed', 'help,', 'while', 'putting', 'their', 'own', 'lives', 'on', 'the', 'line.', 'https://t.co/eZPv0vMIz3']\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Letâ€™s', 'make', 'it', 'even', 'Greater', '!!', '#KAG', 'ðŸ‡ºðŸ‡¸', 'https://t.co/y9qoZD5L2z']\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['We', 'have', 'about', '1hr', 'until', 'the', '@cavs', 'tie', 'up', 'the', 'series', '2-2.', \"I'm\", '#ALLin216', '@RepBarbaraLee', 'you', 'scared?', '#roadtovictory']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Congrats', 'to', '@belliottsd', 'on', 'his', 'new', 'gig', 'at', 'SD', 'City', 'Hall.', 'We', 'are', 'glad', 'you', 'will', 'continue', 'to', 'serveâ€¦', 'https://t.co/fkvMw3cqdI']\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['We', 'are', 'really', 'close,', 'we', 'have', 'over', '$3500', 'raised', 'toward', 'the', 'match', 'right', 'now.', 'Whoot!!', '(Thatâ€™s', '$7000', 'for', 'the', 'non-math', 'majors', 'in', 'the', 'room', 'ðŸ˜‚).', 'Help', 'us', 'get', 'there', 'https://t.co/Tu34C472sD', 'https://t.co/QsdQkYpsmC']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Today,', 'the', 'comment', 'period', 'for', '@POTUSâ€™s', 'plan', 'to', 'expand', 'offshore', 'drilling', 'opened', 'to', 'the', 'public.', 'You', 'have', '60', 'days', '(until', 'March', '9)', 'to', 'share', 'why', 'you', 'oppose', 'the', 'proposed', 'program', 'directly', 'with', 'the', 'Trump', 'Administration.', 'Comments', 'can', 'be', 'made', 'by', 'email', 'or', 'mail.', 'https://t.co/BaaYMeJxQn']\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: ['Celebrated', '@ICSEastLAâ€™s', '22', 'years', 'of', 'Eastside', 'commitment', '&amp;', 'saluted', 'community', 'leaders', 'at', 'last', 'nightâ€™s', 'awards', 'dinner!', 'https://t.co/7V7gH8giVB']\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    \n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3025, 'Democratic': 1253}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4087, 'Democratic': 1637})})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "For the results what I can see is:\n",
    "- For True Republicans: Out of tweets actually posted by Republicans, my classifier correctly identified 3025 as Republican, but it mistakenly classified 1253 as Democratic.\n",
    "- For True Democrats: Out of tweets actually posted by Democrats, my classifier correctly identified 1637 as Democratic, but it mistakenly classified 4087 as Republican."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
